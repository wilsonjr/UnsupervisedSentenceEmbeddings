{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from pathlib import Path \n",
    "os.chdir(Path('./..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.12.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised_embeddings import MaskedLanguageModeling\n",
    "from unsupervised_embeddings import SimCSE\n",
    "from unsupervised_embeddings import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "import csv\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = []\n",
    "# dev_dataset = []\n",
    "\n",
    "# with open('notebooks/AllNLI.tsv', 'rt', encoding='utf8') as f_eval:\n",
    "#     reader = csv.DictReader(f_eval, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "#     for row in reader:\n",
    "#         if row['split'] == 'train':\n",
    "#             train_dataset.append(row['sentence2'])\n",
    "#         elif row['split'] == 'dev':\n",
    "#             dev_dataset.append(row['sentence2'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_file(name, inputs):\n",
    "#     with open('notebooks/'+name, 'wt', encoding='utf8') as f:\n",
    "#         for sample in inputs:\n",
    "#             f.write('{}\\n'.format(sample))\n",
    "\n",
    "# save_file('train_nli.csv', train_dataset)\n",
    "# save_file('dev_nli.csv', dev_dataset)\n",
    "\n",
    "# save_file('toy_train_nli.csv', train_dataset[:1000])\n",
    "# save_file('toy_dev_nli.csv', dev_dataset[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm = MaskedLanguageModeling('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 96\n",
      " 10%|█         | 10/96 [00:01<00:10,  8.31it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8903, 'learning_rate': 4.4791666666666673e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 10%|█         | 10/96 [00:01<00:10,  8.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.51419734954834, 'eval_runtime': 0.1358, 'eval_samples_per_second': 736.603, 'eval_steps_per_second': 95.758, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-10\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-10\\config.json\n",
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-10\\pytorch_model.bin\n",
      " 21%|██        | 20/96 [00:05<00:11,  6.53it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.168, 'learning_rate': 3.958333333333333e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 21%|██        | 20/96 [00:05<00:11,  6.53it/s] Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-20\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-20\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1028120517730713, 'eval_runtime': 0.138, 'eval_samples_per_second': 724.609, 'eval_steps_per_second': 94.199, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-20\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-10] due to args.save_total_limit\n",
      " 31%|███▏      | 30/96 [00:09<00:10,  6.05it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0155, 'learning_rate': 3.4375e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 31%|███▏      | 30/96 [00:10<00:10,  6.05it/s] Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-30\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-30\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3068370819091797, 'eval_runtime': 0.152, 'eval_samples_per_second': 657.822, 'eval_steps_per_second': 85.517, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-30\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-20] due to args.save_total_limit\n",
      " 42%|████▏     | 40/96 [00:17<00:13,  4.22it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6783, 'learning_rate': 2.916666666666667e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 42%|████▏     | 40/96 [00:17<00:13,  4.22it/s] Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-40\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-40\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6858184337615967, 'eval_runtime': 0.1399, 'eval_samples_per_second': 714.868, 'eval_steps_per_second': 92.933, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-40\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-30] due to args.save_total_limit\n",
      " 52%|█████▏    | 50/96 [00:21<00:07,  6.45it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7725, 'learning_rate': 2.3958333333333334e-05, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 52%|█████▏    | 50/96 [00:22<00:07,  6.45it/s] Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-50\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-50\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5507357120513916, 'eval_runtime': 0.135, 'eval_samples_per_second': 740.902, 'eval_steps_per_second': 96.317, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-40] due to args.save_total_limit\n",
      " 62%|██████▎   | 60/96 [00:27<00:06,  5.71it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4655, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 62%|██████▎   | 60/96 [00:27<00:06,  5.71it/s] Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-60\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-60\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.370405673980713, 'eval_runtime': 0.143, 'eval_samples_per_second': 699.188, 'eval_steps_per_second': 90.894, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-60\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-50] due to args.save_total_limit\n",
      " 73%|███████▎  | 70/96 [00:31<00:04,  5.74it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6167, 'learning_rate': 1.3541666666666666e-05, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 73%|███████▎  | 70/96 [00:31<00:04,  5.74it/s] Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-70\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-70\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.173738718032837, 'eval_runtime': 0.139, 'eval_samples_per_second': 719.438, 'eval_steps_per_second': 93.527, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-70\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-60] due to args.save_total_limit\n",
      " 83%|████████▎ | 80/96 [00:37<00:03,  5.09it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7016, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 83%|████████▎ | 80/96 [00:37<00:03,  5.09it/s]Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-80\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-80\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.353186845779419, 'eval_runtime': 0.151, 'eval_samples_per_second': 662.256, 'eval_steps_per_second': 86.093, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-80\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-70] due to args.save_total_limit\n",
      " 94%|█████████▍| 90/96 [00:42<00:01,  5.91it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6531, 'learning_rate': 3.125e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 94%|█████████▍| 90/96 [00:42<00:01,  5.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.369271993637085, 'eval_runtime': 0.136, 'eval_samples_per_second': 735.319, 'eval_steps_per_second': 95.591, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-90\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-90\\config.json\n",
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-90\\pytorch_model.bin\n",
      "Deleting older checkpoint [output\\mlm_distilbert-base-uncased-2022-06-21_21-15-54\\checkpoint-80] due to args.save_total_limit\n",
      " 99%|█████████▉| 95/96 [00:45<00:00,  2.94it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 96/96 [00:46<00:00,  2.08it/s]\n",
      "Configuration saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 46.2082, 'train_samples_per_second': 64.923, 'train_steps_per_second': 2.078, 'train_loss': 1.657782365878423, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\pytorch_model.bin\n",
      "tokenizer config file saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\tokenizer_config.json\n",
      "Special tokens file saved in output/mlm_distilbert-base-uncased-2022-06-21_21-15-54\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unsupervised_embeddings.mlm.MaskedLanguageModeling at 0x1b4a0481760>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm.set_datasets('notebooks/toy_train_nli.csv', 'notebooks/toy_dev_nli.csv') \\\n",
    "    .train(epochs=3, batch_size=32, info_steps=10) \\\n",
    "        .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4224a284912126f805ae0ee160b4a432bf2336f134b0772df0c6ad7ad36981c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
